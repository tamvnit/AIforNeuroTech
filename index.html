<!DOCTYPE html>
<!-- saved from url=(0039)https:// -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Special Topic in Computer Science 189.36</title>
  <link rel="stylesheet" href="./Special Topic in Computer Science 189.36_files/style.css">
</head>
<body>

  <!-- Header -->
  <header>
    <!-- Dartmouth Logo -->
    <img src="./Special Topic in Computer Science 189.36_files/dartmouth_logo.png" alt="Dartmouth Logo" class="dartmouth-logo">
    <h1>Special Topic in Computer Science 189.36</h1>
    <p>Applied AI for Wearable Neurotech</p>
  </header>

  <!-- Main Content -->
  <main>

    <!-- Visible Section (up to "READ MORE") -->
    <section>
      <h2>Course Description</h2>
      <p>
        Imagine this: Devices like Apple Watch, Fitbit, or smart rings have already transformed
        health monitoring by leveraging continuous heart rate data to reveal insights into our
        physical well-being. Now, imagine accessing even richer insights—directly from your brain.
        What could real-time brain data uncover about your mental state, focus, or sleep patterns?
        How could it help you achieve peak performance, accelerate learning, or even induce lucid
        dreams? This course explores the cutting-edge realm of AI-powered neurotechnology, 
        transforming brain data into the next frontier for health monitoring, cognitive enhancement, 
        and human-computer interaction.
      </p>
      <p>
        This course explores the potential of AI-driven neurotechnology, a field at the intersection
        of machine learning, neuroscience, and wearable systems. By leveraging real-time brain data
        through EEG-based devices, students will gain hands-on experience designing and developing
        digital health solutions. These solutions aim to enhance cognitive performance, monitor
        mental health, and facilitate applications like lucid dream induction and cognitive state
        classification. Combining foundational research, practical coding assignments, and a capstone
        project, this course equips students with cutting-edge skills to innovate in the rapidly
        evolving landscape of neurotechnology.
      </p>

      <h2>Course Objectives</h2>
      <p>
        By the end of this course, students will:
        </p><ol>
          <li>Analyze the state-of-the-art research in wearable EEG and brain-computer interfaces.</li>
          <li>Understand ethical practices and experimental protocols for conducting wearable EEG studies.</li>
          <li>Acquire, preprocess, and label brain signal data for real-time applications.</li>
          <li>Apply AI and machine learning techniques to classify cognitive and emotional states.</li>
          <li>Design and prototype healthcare solutions using EEG-based wearable systems, integrating feedback mechanisms.</li>
          <li>Collaborate effectively on interdisciplinary projects and communicate findings through presentations and reports.</li>
        </ol>
      <p></p>

      <h2>Why Take This Course?</h2>
      <p>
        This hands-on course equips students with interdisciplinary skills at the intersection of
        AI/ML, neuroscience, and wearable technology. Ideal for aspiring innovators, engineers, and
        researchers in health tech, the course bridges theory and application, paving the way for
        impactful careers in cognitive enhancement and human-computer interaction.
      </p>

      <h2>Course Details</h2>
      <p>
        <strong>Instructor:</strong> Tam Vu (<a href="mailto:tam.n.vu@dartmouth.edu">tam.n.vu@dartmouth.edu</a>)<br>
        <strong>Class Schedule:</strong> Tuesday and Thursday - Time (TBD), 10 weeks<br>
        <strong>Course Workload:</strong> Recommended 15-20 hours per week<br>
        <strong>Course Credits:</strong> 3 credits<br>
        <strong>Prerequisites:</strong> Only offered for Graduate Level (OS (COSC 58), AI (COSC 76), Algorithms (COSC 31))<br>
        <strong>Distributive Requirements:</strong> TAS<br>
        <strong>Enrollment Cap:</strong> 20 students (hands-on, collaborative learning)<br>
        <strong>Course Communications:</strong> Canvas for assignments/grades; Piazza for discussion
      </p>

      <h2>Required IP before Enrollment</h2>
      <p>
        If you meet these prerequisites and wish to proceed, please complete the following form: 
        <a href="https://docs.google.com/forms/d/1vHeIYCxs98TnM5GIlKONZo09yTTf8ZZpwg7pb06MEVo/edit">
          Google Form
        </a>.<br>
        Please note that slots are limited and will be granted on a first-come, first-served basis.
        We will confirm your IP status within three working days.
      </p>

      <h2>Course Outline</h2>
      <p>
        <strong>Week 1-3: Paper Review &amp; Problem Formation</strong><br>
        Review key papers on cognitive EEG, brain states, and audio stimulation effects.<br>
        Discuss non-invasive wearables for real-time data collection and stimulation.<br>
        Form project teams and define research questions.
      </p>
      <p>
        <strong>Week 4: Data collection protocol design</strong><br>
        Data collection methods and best practices<br>
        Labeling automation<br>
        Data sanitization
      </p>
      <p>
        <strong>Weeks 5–9: Solution Development and Evaluation</strong><br>
        Signal acquisition: EEG, EMG, and EOG data integration.<br>
        Signal Processing: Filtering, artifact removal, and segmentation.<br>
        Data collection and Data labeling<br>
        AI model development: Model selection; training; hyperparameter tuning; evaluation<br>
        System integration: Deploy the model on a compatible platform (e.g., TensorFlow Lite) or remote server.<br>
        System evaluation: Test the integrated system for accuracy, latency, reliability in real-world conditions
      </p>
      <p>
        <strong>Week 10: Final Presentations</strong><br>
        Presenting solutions and findings.<br>
        Peer and instructor feedback.<br>
        Discussion on future research and applications.
      </p>

      <h2>Hands-on Project</h2>
      <p>
        This hands-on project requires students to design and implement a system that integrates
        hardware and software for tracking and enhancing cognitive functions, with project steps
        tailored to specific objectives. Students will begin by selecting and configuring a wearable
        device capable of acquiring signals such as EEG, EOG, or EMG, and interfacing the device with
        a software application using APIs or SDKs. They will design and execute a data collection
        protocol that meets the project needs, gather human subject data, then label it (e.g.,
        relaxed, stressed, engaged). Using this labeled data, they will train an AI agent leveraging
        publicly available open-source models (ChatGPT, DeepSeek, LLaMA) to classify brain states or
        control an actuator. Finally, students will build an end-to-end system integrating hardware,
        data processing, AI, and optional actuation, evaluating its performance with a small user
        group.
      </p>

      <h2>Potential Project Topics (Subject to Change)</h2>
      <ul>
        <li>Lucid Dream Induction and Detection</li>
        <li>Mood Fluctuation Detection and Stabilization</li>
        <li>Engagement Level Monitoring and Enhancement</li>
        <li>Brain Fatigue Monitoring System</li>
        <li>Subliminal Learning Optimization</li>
        <li>Depression Early Warning System</li>
        <li>Eating Behavior Analysis and Intervention</li>
      </ul>

      <!-- "READ MORE" Marker -->
    </section>

    <!-- Hidden Section (after "READ MORE") -->
    <section id="more" style="display: none;">

      <h2>Assessment and Evaluation</h2>
      <p>
        <strong>Participation (Week 1 - Week 10): 10%</strong><br>
        - Requires minimum 80% class attendance<br><br>
        <strong>Project Proposal (Week 3): 10%</strong><br>
        - Research background and objectives<br>
        - Proposed methodology and overall system overview<br>
        - Project Timeline<br>
        - Evaluation metrics and clear definitions of done<br><br>
        <strong>Data Collection Protocol (Week 4): 10%</strong><br>
        - Detailed and feasible data collection plan<br>
        - Data labeling and sanitization methods<br>
        - Quality control and assurance measures<br><br>
        <strong>Hands-on Project (Week 9): 50%</strong><br>
        - Weekly implementation progress<br>
        - AI/ML algorithms for EEG data analysis<br>
        - Prototype development<br>
        - Technical report (methods, results, insights)<br><br>
        <strong>Final Presentation (Week 10): 20%</strong><br>
        - Clear communication of project goals/outcomes<br>
        - Quality of visual aids and delivery<br>
        - Ability to answer questions and discuss future applications
      </p>

      <h2>Late Work</h2>
      <p>
        Grading penalties are 25% within 24 hours late, 50% within one week, and by request otherwise.
      </p>

      <h2>Academic Honor Principle</h2>
      <p>
        Students are expected to adhere to Dartmouth's Academic Honor Principle. For more information,
        please review the Academic Honor Policy for Undergraduate Students in Arts and Sciences.
      </p>

      <h2>Group Work &amp; Collaboration</h2>
      <p>
        In this course, we embrace a collaborative approach that mirrors the environment of a research lab.
        We believe that science and learning thrive on open communication, shared ideas, and collective
        problem-solving. Feel free to work together on assignments (unless stated otherwise). Ensure everyone
        contributes and understands the work. Give credit; acknowledge collaborators and cite sources.
      </p>

      <h2>Use of Generative AI</h2>
      <p>
        Since this class is all about augmenting our abilities with Generative AI, it’s okay for you to do the same.
        However, use it critically. Do not generate your first draft. Write in your own style and voice. Be mindful
        of biases and verify content for clarity and accuracy.
      </p>

      <h2>Mental Health and Wellness</h2>
      <p>
        The academic environment can be challenging. Dartmouth offers resources such as the Counseling Center
        and the Student Wellness Center. If you need immediate assistance, call (603) 646-9442 <a href="http://voice.google.com/calls?a=nc,%2B16036469442" class="gv-tel-link" target="_blank" rel="noopener" title="Call +1 603-646-9442 via Google Voice"></a>at any time.
        Please let me know of anything that may hinder your success in this course.
      </p>

      <h2>Title IX</h2>
      <p>
        Dartmouth does not tolerate sex or gender-based discrimination or harassment.
        For more info, visit <a href="https://sexual-respect.dartmouth.edu/">sexual-respect.dartmouth.edu</a>.
        I am required to share disclosures of sexual or gender-based misconduct with the Title IX office.
      </p>

      <h2>Socioeconomic Differences and Financial Difficulty</h2>
      <p>
        Our community is composed of students from varied financial backgrounds. If you face
        financial challenges related to this class, please contact me or a financial aid officer.
      </p>

      <h2>Religious Observances</h2>
      <p>
        If you have a religious observance that conflicts with the course schedule, please inform me
        by the second week of the term to discuss adjustments.
      </p>

      <h2>Student Accessibility and Accommodations</h2>
      <p>
        Students requiring disability-related accommodations must register with Student Accessibility
        Services (SAS). An accommodation email should be sent to me in advance of the need. All inquiries
        remain confidential.
      </p>

    </section>

    <!-- Read More Button -->
    <button id="myBtn" onclick="toggleReadMore()">Read more</button>

  </main>

  <!-- Footer -->
  <footer>
    <p>© 2025 – Applied AI for Wearable Neurotech</p>
  </footer>

  <!-- Read More Toggle Script -->
  <script>
    function toggleReadMore() {
      const dots = document.querySelector("section p strong"); // The "READ MORE" marker
      const moreSection = document.getElementById("more");
      const btnText = document.getElementById("myBtn");

      if (moreSection.style.display === "none") {
        // Show hidden content
        moreSection.style.display = "block";
        if (dots) dots.style.display = "none"; // hide the "READ MORE" text in visible section
        btnText.innerHTML = "Read less";
      } else {
        // Hide content again
        moreSection.style.display = "none";
        if (dots) dots.style.display = "inline";
        btnText.innerHTML = "Read more";
      }
    }
  </script>



</body></html>